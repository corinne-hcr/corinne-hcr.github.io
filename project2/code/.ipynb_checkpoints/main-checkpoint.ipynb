{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from scipy import signal\n",
    "# from scipy.ndimage import gaussian_filter\n",
    "import os\n",
    "from pathlib import Path\n",
    "from skimage.transform import resize\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path('results').mkdir(exist_ok=True)\n",
    "Path('results/part1').mkdir(exist_ok=True)\n",
    "Path('results/part2').mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1: Fun with Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Convolutions from Scratch!\n",
    "In this section, I use numpy to process all math calculation, cv2 to read and plt to save img."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_4loops(img, kernel):\n",
    "    if len(img.shape) == 3:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    img = img.astype(np.float64)\n",
    "    kernel = kernel.astype(np.float64)\n",
    "    kernel = np.flip(kernel) #important failed without flipping\n",
    "    \n",
    "    img_h, img_w = img.shape\n",
    "    ker_h, ker_w = kernel.shape\n",
    "    \n",
    "    # Calculate padding\n",
    "    pad_h = ker_h // 2\n",
    "    pad_w = ker_w // 2\n",
    "    \n",
    "    # Pad the image\n",
    "    padded_img = np.pad(img, ((pad_h, pad_h), (pad_w, pad_w)), mode='constant') # pad with 0\n",
    "    \n",
    "    # Initialize output\n",
    "    output = np.zeros((img_h, img_w))\n",
    "    \n",
    "    # 4 nested loops\n",
    "    for i in range(img_h): #iterate every row of img\n",
    "        for j in range(img_w): #iterate every col of img\n",
    "            for ki in range(ker_h): #iterate every row of kernel\n",
    "                for kj in range(ker_w): #iterate every col of kernel\n",
    "                    output[i, j] += padded_img[i + ki, j + kj] * kernel[ki, kj]\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_2loops(img, kernel):\n",
    "    if len(img.shape)==3:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    img = img.astype(np.float64)\n",
    "    kernel = kernel.astype(np.float64)\n",
    "    kernel = np.flip(kernel)\n",
    "    img_h, img_w = img.shape\n",
    "    ker_h, ker_w = kernel.shape\n",
    "    pad_h = ker_h // 2\n",
    "    pad_w = ker_w // 2\n",
    "    padded_img = np.pad(img, ((pad_h, pad_h), (pad_w, pad_w)), mode='constant') # pad with 0\n",
    "    output = np.zeros((img_h, img_w))\n",
    "\n",
    "    # 2 nested loops\n",
    "    for i in range(img_h): # iter row of img\n",
    "        for j in range(img_w): #iter col of img\n",
    "            region = padded_img[i:i+ker_h, j:j+ker_w] #get the 3*3 resion\n",
    "            output[i, j] = np.sum(region * kernel) #vectorized calculation\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare using my cup picture\n",
    "my_img = cv2.imread('my_img.jpg', cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_filter = np.ones((9,9))/81 # 9*9 box filter and normalize\n",
    "\n",
    "# convolutions with box filter\n",
    "con_4loops = convolution_4loops(my_img, box_filter)\n",
    "con_2loops = convolution_2loops(my_img, box_filter)\n",
    "con_scipy = signal.convolve2d(my_img.astype(np.float64), box_filter, mode='same', boundary='symm', fillvalue=0)\n",
    "# Verify implementations are similar\n",
    "print(f\"Difference between 4-loop and scipy: {np.mean(np.abs(con_4loops - con_scipy)):.6f}\")\n",
    "print(f\"Difference between 2-loop and scipy: {np.mean(np.abs(con_2loops - con_scipy)):.6f}\")\n",
    "\n",
    "# Display box filter results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "axes[0, 0].imshow(my_img, cmap='gray')\n",
    "axes[0, 0].set_title('Original Photo')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(con_4loops, cmap='gray')\n",
    "axes[0, 1].set_title('9x9 Box Filter (4-loops)')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[1, 0].imshow(con_2loops, cmap='gray')\n",
    "axes[1, 0].set_title('9x9 Box Filter (2-loops)')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(con_scipy, cmap='gray')\n",
    "axes[1, 1].set_title('9x9 Box Filter (SciPy)')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/part1/box_filter_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply finite difference operators Dx and Dy \n",
    "Dx = np.array([[1, 0, -1]])    # 1x3 horizontal filter\n",
    "Dy = np.array([[1], [0], [-1]]) # 3x1 vertical filter\n",
    "\n",
    "# my_img_float = my_img.astype(np.float64)\n",
    "Dx_float = Dx.astype(np.float64)\n",
    "Dy_float = Dy.astype(np.float64)\n",
    "\n",
    "# Test Dx with all three implementations\n",
    "dx_4loops = convolution_4loops(my_img, Dx)\n",
    "dx_2loops = convolution_2loops(my_img, Dx)  \n",
    "dx_scipy = signal.convolve2d(my_img.astype(np.float64), Dx, mode='same', boundary='symm', fillvalue=0) # use “fill”, the \n",
    "\n",
    "# Test Dy with all three implementations\n",
    "dy_4loops = convolution_4loops(my_img, Dy)\n",
    "dy_2loops = convolution_2loops(my_img, Dy)\n",
    "dy_scipy = signal.convolve2d(my_img.astype(np.float64), Dy, mode='same', boundary='symm', fillvalue=0)\n",
    "\n",
    "# Verify Dx implementations are similar\n",
    "print(f\"Dx - Difference between 4-loop and scipy: {np.mean(np.abs(dx_4loops - dx_scipy)):.6f}\")\n",
    "print(f\"Dx - Difference between 2-loop and scipy: {np.mean(np.abs(dx_2loops - dx_scipy)):.6f}\")\n",
    "\n",
    "# Verify Dy implementations are similar  \n",
    "print(f\"Dy - Difference between 4-loop and scipy: {np.mean(np.abs(dy_4loops - dy_scipy)):.6f}\")\n",
    "print(f\"Dy - Difference between 2-loop and scipy: {np.mean(np.abs(dy_2loops - dy_scipy)):.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Dx and Dy results\n",
    "# the results are not in abs since the plots with \n",
    "#grey background are much easier to see the differences\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "axes[0, 0].imshow(dx_4loops, cmap='gray')\n",
    "axes[0, 0].set_title('Dx (4-loops)')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(dx_2loops, cmap='gray')\n",
    "axes[0, 1].set_title('Dx (2-loops)')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[0, 2].imshow(dx_scipy, cmap='gray')\n",
    "axes[0, 2].set_title('Dx (SciPy)')\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "axes[1, 0].imshow(dy_4loops, cmap='gray')\n",
    "axes[1, 0].set_title('Dy (4-loops)')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(dy_2loops, cmap='gray')\n",
    "axes[1, 1].set_title('Dy (2-loops)')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "axes[1, 2].imshow(dy_scipy, cmap='gray')\n",
    "axes[1, 2].set_title('Dy (SciPy)')\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/part1/derivative_filters_comparison.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.2: Finite Difference Operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cameraman = cv2.imread('cameraman_image.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "print(f\"cameraman image shape: {cameraman.shape}\")\n",
    "\n",
    "partial_x = signal.convolve2d(cameraman.astype(np.float64), Dx, mode='same', boundary='symm', fillvalue=0)\n",
    "partial_y = signal.convolve2d(cameraman.astype(np.float64), Dy, mode='same', boundary='symm', fillvalue=0)\n",
    "gradient_magnitude = np.sqrt(partial_x**2 + partial_y**2)\n",
    "\n",
    "percentiles_to_try = [90, 95, 95.5, 96, 96.5, 97, 98, 99]\n",
    "print(\"Testing different thresholds to suppress noise:\")\n",
    "\n",
    "for p in percentiles_to_try:\n",
    "    thresh = np.percentile(gradient_magnitude, p)\n",
    "    edges = gradient_magnitude > thresh\n",
    "    edge_percentage = np.sum(edges) / edges.size * 100\n",
    "    print(f\"  {p}th percentile: threshold={thresh:.1f}, {edge_percentage:.2f}% edge pixels\")\n",
    "\n",
    "\n",
    "\n",
    "threshold = np.percentile(gradient_magnitude, 95) \n",
    "edge_image = gradient_magnitude > threshold\n",
    "\n",
    "print(f\"Threshold: {threshold:.1f}\")\n",
    "print(f\"Edge pixels: {np.sum(edge_image)}/{edge_image.size} ({np.sum(edge_image)/edge_image.size*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "axes[0, 0].imshow(cameraman, cmap='gray')\n",
    "axes[0, 0].set_title('Original Cameraman')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(partial_x, cmap='gray')\n",
    "axes[0, 1].set_title('Partial Derivative ∂I/∂x')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[0, 2].imshow(partial_y, cmap='gray')\n",
    "axes[0, 2].set_title('Partial Derivative ∂I/∂y')\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "axes[1, 0].imshow(gradient_magnitude, cmap='gray')\n",
    "axes[1, 0].set_title('Gradient Magnitude')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(edge_image, cmap='gray')\n",
    "axes[1, 1].set_title(f'Binary Edges (threshold={threshold:.1f})')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "\n",
    "axes[1, 2].axis('off')  \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/part1/finite_difference_edges.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.3: Derivative of Gaussian (DoG) Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different kernel sizes and sigma values\n",
    "kernel_sizes = [9, 15, 21]\n",
    "sigmas = [1.0, 2.0, 3.0]\n",
    "\n",
    "print(\"Testing different Gaussian filter parameters:\")\n",
    "fig, axes = plt.subplots(len(kernel_sizes), len(sigmas), figsize=(12, 12))\n",
    "\n",
    "for i, ksize in enumerate(kernel_sizes):\n",
    "    for j, sig in enumerate(sigmas):\n",
    "        gaussian_1d_test = cv2.getGaussianKernel(ksize, sig)\n",
    "        gaussian_2d_test = np.outer(gaussian_1d_test, gaussian_1d_test)\n",
    "        \n",
    "        axes[i, j].imshow(gaussian_2d_test, cmap='gray')\n",
    "        axes[i, j].set_title(f'Size={ksize}, σ={sig}')\n",
    "        axes[i, j].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/part1/gaussian_filter_comparison.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Select parameters based on balance of smoothing and detail preservation\n",
    "kernel_size = 15  # Large enough for effective smoothing\n",
    "sigma = 2.0       # Good balance of noise reduction and detail preservation\n",
    "\n",
    "print(f\"\\nSelected parameters: kernel_size={kernel_size}, sigma={sigma}\")\n",
    "\n",
    "# Create 2D Gaussian filter\n",
    "gaussian_1d = cv2.getGaussianKernel(kernel_size, sigma)\n",
    "gaussian_2d = np.outer(gaussian_1d, gaussian_1d)\n",
    "\n",
    "# Apply Gaussian blur, then difference operators (method 1)\n",
    "blurred_image = signal.convolve2d(cameraman.astype(np.float64), gaussian_2d, mode='same', boundary='symm')\n",
    "partial_x_blurred = signal.convolve2d(blurred_image, Dx, mode='same', boundary='symm')\n",
    "partial_y_blurred = signal.convolve2d(blurred_image, Dy, mode='same', boundary='symm')\n",
    "gradient_magnitude_blurred = np.sqrt(partial_x_blurred**2 + partial_y_blurred**2)\n",
    "\n",
    "# Create DoG filters and apply directly (method 2)\n",
    "DoG_x = signal.convolve2d(gaussian_2d, Dx, mode='same')\n",
    "DoG_y = signal.convolve2d(gaussian_2d, Dy, mode='same')\n",
    "\n",
    "dog_x_result = signal.convolve2d(cameraman.astype(np.float64), DoG_x, mode='same', boundary='symm')\n",
    "dog_y_result = signal.convolve2d(cameraman.astype(np.float64), DoG_y, mode='same', boundary='symm')\n",
    "gradient_magnitude_dog = np.sqrt(dog_x_result**2 + dog_y_result**2)\n",
    "\n",
    "# Verify equivalence\n",
    "difference = np.abs(gradient_magnitude_blurred - gradient_magnitude_dog)\n",
    "max_difference = np.max(difference)\n",
    "print(f\"Max difference between two approaches: {max_difference:.6f}\")\n",
    "print(f\"Results are equivalent: {max_difference < 1.0}\")\n",
    "\n",
    "# Compare with Part 1.2 \n",
    "# threshold\n",
    "threshold_blurred = np.percentile(gradient_magnitude_blurred, 95)\n",
    "\n",
    "edge_original = gradient_magnitude > threshold\n",
    "edge_blurred = gradient_magnitude_blurred > threshold_blurred\n",
    "\n",
    "# Viz\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
    "\n",
    "# Row 1: Gradient magnitude comparison\n",
    "axes[0, 0].imshow(gradient_magnitude, cmap='gray')\n",
    "axes[0, 0].set_title('Part 1.2: No Gaussian')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(gradient_magnitude_blurred, cmap='gray')\n",
    "axes[0, 1].set_title('Gaussian + Difference')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[0, 2].imshow(gradient_magnitude_dog, cmap='gray')\n",
    "axes[0, 2].set_title('DoG Result')\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "# Row 2: Edge detection results\n",
    "axes[1, 0].imshow(edge_original, cmap='gray')\n",
    "axes[1, 0].set_title('Edges: No Gaussian')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(edge_blurred, cmap='gray')\n",
    "axes[1, 1].set_title('Edges: With Gaussian')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "axes[1, 2].imshow(blurred_image, cmap='gray')\n",
    "axes[1, 2].set_title('Gaussian Blurred Image')\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "# Row 3: DoG filters as required by assignment\n",
    "axes[2, 0].imshow(DoG_x, cmap='gray')\n",
    "axes[2, 0].set_title('DoG_x Filter')\n",
    "axes[2, 0].axis('off')\n",
    "\n",
    "axes[2, 1].imshow(DoG_y, cmap='gray')\n",
    "axes[2, 1].set_title('DoG_y Filter')\n",
    "axes[2, 1].axis('off')\n",
    "\n",
    "axes[2, 2].imshow(gaussian_2d, cmap='gray')\n",
    "axes[2, 2].set_title('2D Gaussian Filter')\n",
    "axes[2, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/part1/dog_edge_detection_comparison.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"What differences do you see?\")\n",
    "print(\"1. Noise Reduction: Gaussian preprocessing significantly reduces noise\")\n",
    "print(\"2. Cleaner Edges: Background clutter is suppressed\")\n",
    "print(\"3. Better Connectivity: Main edges are more continuous\")\n",
    "\n",
    "print(f\"\\nEdge pixel percentages:\")\n",
    "print(f\"Original method: {np.sum(edge_original)/edge_original.size*100:.1f}%\")\n",
    "print(f\"With Gaussian: {np.sum(edge_blurred)/edge_blurred.size*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nVerification: Two DoG approaches are mathematically equivalent (diff={max_difference:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Fun with Frequencies!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_filter(image, sigma):\n",
    "    ksize = int(6 * sigma) // 2 * 2 + 1\n",
    "    \n",
    "    kernel_1d = cv2.getGaussianKernel(ksize, sigma)\n",
    "    kernel_2d = kernel_1d @ kernel_1d.T\n",
    "    \n",
    "    if len(image.shape) == 3:\n",
    "        filtered = np.zeros_like(image)\n",
    "        for i in range(image.shape[2]):\n",
    "            filtered[:,:,i] = signal.convolve2d(image[:,:,i], kernel_2d, \n",
    "                                                mode='same', boundary='symm')\n",
    "        return filtered\n",
    "    else:\n",
    "        return signal.convolve2d(image, kernel_2d, mode='same', boundary='symm')\n",
    "\n",
    "        \n",
    "def unsharp_mask(image, sigma, alpha):\n",
    "    # low-pass filter\n",
    "    blurred = gaussian_filter(image, sigma)\n",
    "    \n",
    "    # high frequencies \n",
    "    high_freq = image - blurred\n",
    "    \n",
    "    sharpened = image + alpha * high_freq\n",
    "    \n",
    "    sharpened = np.clip(sharpened, 0, 1)\n",
    "    \n",
    "    return sharpened, blurred, high_freq\n",
    "\n",
    "\n",
    "\n",
    "test_image = plt.imread('taj.jpg') / 255.0\n",
    "\n",
    "# # Test different sigma values (blur strength)\n",
    "# sigmas = [1.0, 2.0, 3.0]\n",
    "# alphas = [1.0, 1.5, 2.0]\n",
    "\n",
    "# print(\"Testing different parameter combinations:\")\n",
    "# fig, axes = plt.subplots(len(sigmas), len(alphas), figsize=(12, 12))\n",
    "\n",
    "# for i, sigma in enumerate(sigmas):\n",
    "#     for j, alpha in enumerate(alphas):\n",
    "#         sharpened, _, _ = unsharp_mask(test_image, sigma, alpha)\n",
    "#         axes[i, j].imshow(sharpened)\n",
    "#         axes[i, j].set_title(f'σ={sigma}, α={alpha}')\n",
    "#         axes[i, j].axis('off')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# select optimal parameters based on visual inspection\n",
    "sigma = 2.0  # Good balance of detail preservation and noise reduction\n",
    "alpha = 1.5  # Noticeable sharpening without artifacts\n",
    "\n",
    "\n",
    "\n",
    "# Part 1: Taj Mahal demonstration (as required by assignment)\n",
    "print(\"Taj Mahal Sharpening Demo\")\n",
    "taj_image = plt.imread('taj.jpg') / 255.0  # Use the taj image from assignment\n",
    "\n",
    "taj_sharpened, taj_blurred, taj_high_freq = unsharp_mask(taj_image, sigma, alpha)\n",
    "\n",
    "# Display Taj Mahal results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "axes[0, 0].imshow(taj_image)\n",
    "axes[0, 0].set_title('Original Taj Mahal')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(taj_blurred)\n",
    "axes[0, 1].set_title('Blurred (Low-pass)')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[1, 0].imshow(taj_high_freq + 0.5)  # Add 0.5 to center around gray\n",
    "axes[1, 0].set_title('High Frequencies')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(taj_sharpened)\n",
    "axes[1, 1].set_title(f'Sharpened (α={alpha})')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/part2/part1_taj_mahal_sharpening.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Part 2: Orange cat demonstration\n",
    "print(\"Orange Cat Sharpening Demo\")\n",
    "orange_cat = plt.imread('orange_cat.jpg') / 255.0  # Your chosen image\n",
    "\n",
    "# Apply unsharp masking\n",
    "orange_sharpened, orange_blurred, orange_high_freq = unsharp_mask(orange_cat, sigma, alpha)\n",
    "\n",
    "# Display orange cat results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "axes[0, 0].imshow(orange_cat)\n",
    "axes[0, 0].set_title('Original Orange Cat')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(orange_blurred)\n",
    "axes[0, 1].set_title('Blurred (Low-pass)')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[1, 0].imshow(orange_high_freq + 0.5)\n",
    "axes[1, 0].set_title('High Frequencies')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(orange_sharpened)\n",
    "axes[1, 1].set_title(f'Sharpened (α={alpha})')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/part2/part2_orange_cat_sharpening.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Part 3: Evaluation test with white cat\n",
    "print(\"Evaluation: Sharp → Blur → Sharpen on White Cat\")\n",
    "\n",
    "\n",
    "white_cat = plt.imread('white_cat.jpg') / 255.0  \n",
    "\n",
    "# blur\n",
    "artificially_blurred = gaussian_filter(white_cat, sigma=3.0)\n",
    "\n",
    "# then sharpen\n",
    "resharpened, _, _ = unsharp_mask(artificially_blurred, sigma=2.0, alpha=2.0)\n",
    "\n",
    "# compare original vs blurred vs resharpened\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].imshow(white_cat)\n",
    "axes[0].set_title('Original White Cat (Sharp)')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(artificially_blurred)\n",
    "axes[1].set_title('Artificially Blurred')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(resharpened)\n",
    "axes[2].set_title('Attempt to Re-sharpen')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/part2/part3_evaluation_test.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Observations:\")\n",
    "print(\"1. Unsharp masking enhances edge details and makes images appear sharper\")\n",
    "print(\"2. However, once information is lost through blurring, it cannot be perfectly recovered\")\n",
    "print(\"3. Re-sharpening a blurred image often introduces artifacts and cannot restore original detail\")\n",
    "print(\"4. The method works best for enhancing existing sharp images, not recovering lost detail\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.2: Hybrid Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_image(im1, im2, sigma1, sigma2):\n",
    "    \n",
    "    # Apply 2D Gaussian filter for low-pass \n",
    "    low_frequencies = cv2.GaussianBlur(im1, (0, 0), sigma1)\n",
    "    \n",
    "    # High-pass = original - Gaussian-filtered image\n",
    "    high_frequencies = im2 - cv2.GaussianBlur(im2, (0, 0), sigma2)\n",
    "    \n",
    "    # add two imgs\n",
    "    hybrid = low_frequencies + high_frequencies\n",
    "    hybrid = np.clip(hybrid, 0, 1)\n",
    "    \n",
    "    return hybrid\n",
    "\n",
    "\n",
    "def show_frequency_analysis(im1, im2, sigma1, sigma2):        \n",
    "    low_frequencies = cv2.GaussianBlur(im1, (0, 0), sigma1)\n",
    "    high_frequencies = im2 - cv2.GaussianBlur(im2, (0, 0), sigma2)\n",
    "    hybrid = low_frequencies + high_frequencies\n",
    "    hybrid = np.clip(hybrid, 0, 1)\n",
    "    \n",
    "    # change to grey for FFT\n",
    "    if len(im1.shape) == 3:\n",
    "        im1_gray = np.mean(im1, axis=2)\n",
    "        im2_gray = np.mean(im2, axis=2)\n",
    "        low_gray = np.mean(low_frequencies, axis=2)\n",
    "        high_gray = np.mean(high_frequencies, axis=2)\n",
    "        hybrid_gray = np.mean(hybrid, axis=2)\n",
    "    else:\n",
    "        im1_gray = im1\n",
    "        im2_gray = im2\n",
    "        low_gray = low_frequencies\n",
    "        high_gray = high_frequencies\n",
    "        hybrid_gray = hybrid\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # original imgs\n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.imshow(im1_gray, cmap='gray')\n",
    "    plt.title('Original Image 1')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(2, 3, 2)\n",
    "    plt.imshow(im2_gray, cmap='gray')\n",
    "    plt.title('Original Image 2')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # with filter\n",
    "    plt.subplot(2, 3, 3)\n",
    "    plt.imshow(low_gray, cmap='gray')\n",
    "    plt.title('Low-pass Filtered')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(2, 3, 4)\n",
    "    plt.imshow(high_gray + 0.5, cmap='gray')  # +0.5 for prestentation\n",
    "    plt.title('High-pass Filtered')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(2, 3, 5)\n",
    "    plt.imshow(hybrid_gray, cmap='gray')\n",
    "    plt.title('Hybrid Image')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # FFT analysis\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.imshow(np.log(np.abs(np.fft.fftshift(np.fft.fft2(im1_gray)))), cmap='gray')\n",
    "    plt.title('FFT of Image 1')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(2, 3, 2)\n",
    "    plt.imshow(np.log(np.abs(np.fft.fftshift(np.fft.fft2(im2_gray)))), cmap='gray')\n",
    "    plt.title('FFT of Image 2')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(2, 3, 3)\n",
    "    plt.imshow(np.log(np.abs(np.fft.fftshift(np.fft.fft2(low_gray)))), cmap='gray')\n",
    "    plt.title('FFT of Low-pass')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(2, 3, 4)\n",
    "    plt.imshow(np.log(np.abs(np.fft.fftshift(np.fft.fft2(high_gray)))), cmap='gray')\n",
    "    plt.title('FFT of High-pass')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(2, 3, 5)\n",
    "    plt.imshow(np.log(np.abs(np.fft.fftshift(np.fft.fft2(hybrid_gray)))), cmap='gray')\n",
    "    plt.title('FFT of Hybrid')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results/part2/hybrid_fft_analysis.jpg', bbox_inches='tight', dpi=150)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    return hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra hybrid imgs\n",
    "def show_extra_result(im1, im2, hybrid):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(im1)\n",
    "    plt.title('Input 1')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(im2)\n",
    "    plt.title('Input 2')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(hybrid)\n",
    "    plt.title('Hybrid Result')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results/part2/hybrid_extra_result.jpg', bbox_inches='tight', dpi=150)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma1 = 12  # low-pass filter, the greater the blurrer [10,11,12,13,14,15,16]\n",
    "sigma2 = 6   # high-pass filter, more details with smaller sigma [5,6,7,8,9,10]\n",
    "tiger = plt.imread('hybrid_python/tiger_aligned.jpg') / 255.0\n",
    "cat = plt.imread('hybrid_python/cat_aligned_t.jpg') / 255.0\n",
    "hybrid = hybrid_image(tiger, cat, sigma1, sigma2)\n",
    "plt.imsave('results/part2/hybrid_tiger_cat.jpg', hybrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(hybrid)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "show_extra_result(tiger, cat, hybrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cat2 = plt.imread('hybrid_python/cat_aligned_d.jpg') / 255.0\n",
    "\n",
    "dog = plt.imread('hybrid_python/dog_aligned.jpg') / 255.0\n",
    "\n",
    "hybrid2 = hybrid_image(dog, cat2, sigma1, sigma2)\n",
    "show_extra_result(dog, cat2, hybrid2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2.2: Derek + Nutmeg Hybrid Image\n",
    "from hybrid_python.align_image_code import align_images\n",
    "\n",
    "derek = plt.imread('hybrid_python/derek_aligned.jpg') / 255.0\n",
    "nutmeg = plt.imread('hybrid_python/nutmeg_aligned.jpg') / 255.0\n",
    "\n",
    "hybrid_derek_nutmeg = hybrid_image(derek, nutmeg, sigma1, sigma2)\n",
    "show_frequency_analysis(derek, nutmeg, sigma1, sigma2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Part 2.3: Gaussian and Laplacian Stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_stack(image, N, sigma=2):\n",
    "    \"\"\"Create Gaussian stack (no downsampling)\"\"\"\n",
    "    stack = [image.copy()]\n",
    "    for i in range(1, N):\n",
    "        if len(image.shape) == 3:\n",
    "            blurred = np.stack([gaussian_filter(stack[-1][:,:,c], sigma * 2**(i-1)) \n",
    "                               for c in range(3)], axis=2)\n",
    "        else:\n",
    "            blurred = gaussian_filter(stack[-1], sigma * 2**(i-1))\n",
    "        stack.append(blurred)\n",
    "    return stack\n",
    "\n",
    "def laplacian_stack(g_stack):\n",
    "    \"\"\"Create Laplacian stack from Gaussian stack\"\"\"\n",
    "    return [g_stack[i] - g_stack[i+1] for i in range(len(g_stack)-1)] + [g_stack[-1]]\n",
    "\n",
    "def show_stacks(img1, img2, N, sigma=2, name1=\"Orange\", name2=\"Apple\"):\n",
    "    \"\"\"Complete visualization for Part 2.3\"\"\"\n",
    "    \n",
    "    # stacks\n",
    "    g1, g2 = gaussian_stack(img1, N, sigma), gaussian_stack(img2, N, sigma)\n",
    "    l1, l2 = laplacian_stack(g1), laplacian_stack(g2)\n",
    "    \n",
    "    # display Gaussian stacks\n",
    "    fig, axes = plt.subplots(2, N, figsize=(3*N, 6))\n",
    "    fig.suptitle(f'Gaussian Stacks (sigma={sigma})', fontsize=14)\n",
    "    for i in range(N):\n",
    "        axes[0,i].imshow(np.clip(g1[i], 0, 1))\n",
    "        axes[0,i].set_title(f'{name1} G[{i}]', fontsize=10)\n",
    "        axes[0,i].axis('off')\n",
    "        axes[1,i].imshow(np.clip(g2[i], 0, 1))\n",
    "        axes[1,i].set_title(f'{name2} G[{i}]', fontsize=10)\n",
    "        axes[1,i].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # display Laplacian stacks\n",
    "    fig, axes = plt.subplots(2, N, figsize=(3*N, 6))\n",
    "    fig.suptitle('Laplacian Stacks', fontsize=14)\n",
    "    for i in range(N):\n",
    "        axes[0,i].imshow(np.clip(l1[i] + 0.5, 0, 1))\n",
    "        axes[0,i].set_title(f'{name1} L[{i}]', fontsize=10)\n",
    "        axes[0,i].axis('off')\n",
    "        axes[1,i].imshow(np.clip(l2[i] + 0.5, 0, 1))\n",
    "        axes[1,i].set_title(f'{name2} L[{i}]', fontsize=10)\n",
    "        axes[1,i].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "     \n",
    "    return g1, g2, l1, l2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_blending(l1, l2, g_mask, img1_name=\"Apple\", img2_name=\"Orange\"):\n",
    "    N = len(l1)\n",
    "    l_blend = []\n",
    "    \n",
    "    for i in range(N):\n",
    "        m = np.stack([g_mask[i]]*3, axis=2) if len(l1[i].shape)==3 else g_mask[i]\n",
    "        l_blend.append(l1[i] * m + l2[i] * (1-m))\n",
    "    \n",
    "    # Visualize\n",
    "    fig, axes = plt.subplots(N, 3, figsize=(12, 3*N))\n",
    "    fig.suptitle('Laplacian Blending (Figure 3.42)', fontsize=14)\n",
    "    \n",
    "    for i in range(N):\n",
    "        m = np.stack([g_mask[i]]*3, axis=2) if len(l1[i].shape)==3 else g_mask[i]\n",
    "        \n",
    "        axes[i,0].imshow(np.clip(l1[i]*m + 0.5, 0, 1))\n",
    "        axes[i,0].set_title(f'{img1_name} L{i}×Mask')\n",
    "        axes[i,0].axis('off')\n",
    "        \n",
    "        axes[i,1].imshow(np.clip(l2[i]*(1-m) + 0.5, 0, 1))\n",
    "        axes[i,1].set_title(f'{img2_name} L{i}×(1-M)')\n",
    "        axes[i,1].axis('off')\n",
    "        \n",
    "        axes[i,2].imshow(np.clip(l_blend[i] + 0.5, 0, 1))\n",
    "        axes[i,2].set_title(f'Blended L{i}')\n",
    "        axes[i,2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return np.sum(l_blend, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orange = plt.imread('./orange.jpeg') / 255.0\n",
    "apple = plt.imread('./apple.jpeg') / 255.0\n",
    "\n",
    "# resize if needed (make them same size)\n",
    "if orange.shape != apple.shape:\n",
    "    from PIL import Image\n",
    "    size = (min(orange.shape[1], apple.shape[1]), min(orange.shape[0], apple.shape[0]))\n",
    "    orange = np.array(Image.fromarray((orange*255).astype(np.uint8)).resize(size)) / 255.0\n",
    "    apple = np.array(Image.fromarray((apple*255).astype(np.uint8)).resize(size)) / 255.0\n",
    "\n",
    "print(f\"Image shapes: Orange {orange.shape}, Apple {apple.shape}\")\n",
    "\n",
    "# Create and visualize stacks\n",
    "N=5\n",
    "sigma=2\n",
    "g_orange, g_apple, l_orange, l_apple = show_stacks(\n",
    "    orange, apple, \n",
    "    N,        # Number of levels\n",
    "    sigma,    # Base sigma (try 2, 4, or 8)\n",
    "    name1=\"Orange\",\n",
    "    name2=\"Apple\"\n",
    ")\n",
    "\n",
    "\n",
    "# The following is actually for 2.4\n",
    "mask = np.zeros(apple.shape[:2])\n",
    "mask[:, :apple.shape[1]//2] = 1\n",
    "g_mask = gaussian_stack(mask, N=5)\n",
    "\n",
    "oraple = show_blending(l_apple, l_orange, g_mask)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(131); plt.imshow(apple); plt.title('Apple'); plt.axis('off')\n",
    "plt.subplot(132); plt.imshow(orange); plt.title('Orange'); plt.axis('off')\n",
    "plt.subplot(133); plt.imshow(np.clip(oraple, 0, 1)); plt.title('Oraple'); plt.axis('off')\n",
    "plt.savefig('results/part2/oraple_result.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.4: Multiresolution Blending (a.k.a. the oraple!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend_fast(l1, l2, g_mask):\n",
    "    l_blend = []\n",
    "    for i in range(len(l1)):\n",
    "        m = np.stack([g_mask[i]]*3, axis=2)\n",
    "        l_blend.append(l1[i] * m + l2[i] * (1 - m))\n",
    "    return np.sum(l_blend, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacks are created in 2.3 \n",
    "\n",
    "# g_mask also created in 2.3\n",
    "\n",
    "# blending process in 2.3\n",
    "\n",
    "# -------------------- My own creative blend --------------------\n",
    "\n",
    "img1 = plt.imread('water.jpg') / 255.0\n",
    "img2 = plt.imread('mountain.jpg') / 255.0\n",
    "\n",
    "target_size = (512, 512)\n",
    "img1 = resize(img1, target_size, anti_aliasing=True)\n",
    "img2 = resize(img2, target_size, anti_aliasing=True)\n",
    "\n",
    "mask_water= np.zeros(img1.shape[:2])\n",
    "mask_water[img1.shape[0]//2:, :] = 1\n",
    "\n",
    "N=5\n",
    "g1 = gaussian_stack(img1, N, sigma)\n",
    "g2 = gaussian_stack(img2, N, sigma)\n",
    "l1 = laplacian_stack(g1)\n",
    "l2 = laplacian_stack(g2)\n",
    "\n",
    "# Gaussian stack for mask_water\n",
    "g_mask = gaussian_stack(mask_water, N, sigma)\n",
    "\n",
    "result_w_m = blend_fast(l1, l2, g_mask)\n",
    "\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.subplot(141); plt.imshow(img1); plt.title('Water Scene'); plt.axis('off')\n",
    "plt.subplot(142); plt.imshow(img2); plt.title('Mountain Scene'); plt.axis('off')\n",
    "plt.subplot(143); plt.imshow(mask_water, cmap='gray'); plt.title('Mask'); plt.axis('off')\n",
    "plt.subplot(144); plt.imshow(np.clip(result_w_m, 0, 1)); plt.title('Blended Result'); plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/part2/water_mountain_result.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from skimage.color import rgb2hsv\n",
    "from scipy.ndimage import binary_closing, binary_opening, binary_fill_holes, gaussian_filter\n",
    "\n",
    "# another blend\n",
    "cloud_sky = np.array(Image.open('cloud_sky.jpg').resize((512, 512))) / 255.0\n",
    "field_woman = np.array(Image.open('woman_field.jpg').resize((512, 512))) / 255.0\n",
    "\n",
    "print(f\"Images loaded: {cloud_sky.shape}, {field_woman.shape}\")\n",
    "\n",
    "\n",
    "def extract_bright_sky_mask(img, brightness_threshold=0.65, top_bias=0.3):\n",
    "   \n",
    "    if len(img.shape) == 3:\n",
    "        brightness = np.mean(img, axis=2)\n",
    "    else:\n",
    "        brightness = img\n",
    "    \n",
    "    h, w = brightness.shape\n",
    "    y_weight = np.linspace(1 + top_bias, 1 - top_bias, h)  \n",
    "    y_weight = y_weight[:, np.newaxis]  \n",
    "    \n",
    "    weighted_brightness = brightness * y_weight\n",
    "    \n",
    "    sky_mask = (weighted_brightness > brightness_threshold).astype(float) \n",
    "    sky_mask = gaussian_filter(sky_mask, sigma=3)\n",
    "    \n",
    "    return sky_mask\n",
    "\n",
    "# Extract mask\n",
    "mask_sky = extract_bright_sky_mask(field_woman, brightness_threshold=0.6, top_bias=0.3)\n",
    "\n",
    "g1 = gaussian_stack(cloud_sky, N, sigma)\n",
    "g2 = gaussian_stack(field_woman, N, sigma)\n",
    "l1 = laplacian_stack(g1)\n",
    "l2 = laplacian_stack(g2)\n",
    "\n",
    "g_mask2 = gaussian_stack(mask_sky, N, sigma)\n",
    "\n",
    "result_cloud_women = blend_fast(l1, l2, g_mask2)\n",
    "\n",
    "# Show result\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.subplot(141); plt.imshow(cloud_sky); plt.title('Cloud Sky'); plt.axis('off')\n",
    "plt.subplot(142); plt.imshow(field_woman); plt.title('Original'); plt.axis('off')\n",
    "plt.subplot(143); plt.imshow(mask_sky, cmap='gray'); plt.title('Mask'); plt.axis('off')\n",
    "plt.subplot(144); plt.imshow(np.clip(result_cloud_women, 0, 1)); plt.title('result_cloud_women'); plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/part2/result_cloud_women.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# screen + koala\n",
    "screen_x_start, screen_x_end = 207, 299\n",
    "screen_y_start, screen_y_end = 132, 314\n",
    "\n",
    "\n",
    "koala_original = np.array(Image.open('koala.jpg')) / 255.0\n",
    "phone = np.array(Image.open('phone_hand.jpg').resize((512, 512))) / 255.0\n",
    "\n",
    "\n",
    "screen_height = screen_y_end - screen_y_start\n",
    "screen_width = screen_x_end - screen_x_start\n",
    "\n",
    "koala_resized = np.array(Image.fromarray((koala_original * 255).astype(np.uint8))\n",
    "                         .resize((screen_width, screen_height))) / 255.0\n",
    "\n",
    "koala_full = np.zeros((512, 512, 3))\n",
    "koala_full[screen_y_start:screen_y_end, screen_x_start:screen_x_end] = koala_resized\n",
    "\n",
    "\n",
    "mask_screen = np.zeros(phone.shape[:2])\n",
    "mask_screen[screen_y_start:screen_y_end, screen_x_start:screen_x_end] = 1\n",
    "mask_screen = gaussian_filter(mask_screen, sigma=8)\n",
    "\n",
    "#  Build stacks \n",
    "N = 5\n",
    "sigma = 2\n",
    "\n",
    "g1 = gaussian_stack(koala_full, N, sigma)\n",
    "g2 = gaussian_stack(phone, N, sigma)\n",
    "l1 = laplacian_stack(g1)\n",
    "l2 = laplacian_stack(g2)\n",
    "g_mask = gaussian_stack(mask_screen, N, sigma)\n",
    "\n",
    "\n",
    "result_koala_phone = show_blending(l1, l2, g_mask, \n",
    "                       img1_name=\"Koala\", img2_name=\"Phone\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "\n",
    "plt.subplot(151); plt.imshow(koala_original); plt.title('Original Koala'); plt.axis('off')\n",
    "plt.subplot(152); plt.imshow(koala_full); plt.title('Koala (Screen Size)'); plt.axis('off')\n",
    "plt.subplot(153); plt.imshow(phone); plt.title('Phone Hand'); plt.axis('off')\n",
    "plt.subplot(154); plt.imshow(mask_screen, cmap='gray'); plt.title('Screen Mask'); plt.axis('off')\n",
    "plt.subplot(155); plt.imshow(np.clip(result_koala_phone, 0, 1)); plt.title('Koala in Phone'); plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/part2/koala_in_phone_detailed.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOsKM63uuFwrXQsQO/Wc6Nm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (cs180)",
   "language": "python",
   "name": "cs180"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
